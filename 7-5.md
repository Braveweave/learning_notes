#  07-05


---

## Hadoop伪分布式模式：
单机、单一java进程；有HDFS、可以执行文件操作;一般用户调试、开发

两种模式：伪分布式模式、集群模式


1.  下载、拷贝、解压安装文件

`home/hadoop/hadoop-3.0.0`

2.**配置环境**（系统配置文件 .bash_profine\ *.sh\ **\*.xml**）<  SHH 登陆配置 >

 1.etc/hadoop/core-site.xml 内核配置文件

```html
            <configuration>
                <!-- 指明HDFS的访问的web地址和端口 -->
                <property>
                    <name>fs.defaultFS</name>
                    <value>hdfs://localhost:9000</value>
master:9000</value>
                </property>
                <!-- 可以不写 -->
                <property>
                    <name>fs.default.name</name>
                    <value>hdfs://master:9000</value>
                </property>
            </configuration>
```
  
  ----------------
  2.hdfs-site.xml `*-site`节点的配置文件
  
   存文件在文件系统里，多台机器存多个块
   
    etc/hadoop/core-site.xml
```html
            <configuration>
                <!-- 指明HDFS访问的web地址和端口-->
上文件块的复制|备份份数 -->
                <property>
                    <name>dfs.defaultFSreplication</name>
                    <value>http://localhost:9000</value>
1</value>
                </property>
            </configuration>
```
  伪分布模式到此为止
  
  ---------------------------------------------------------------
  
  
  3. `etc/hadoop/mapred-site.xml` 资源分配进程
  4. `etc/hadoop/yarn-site.xml`  计算框架进

  3\4 可选
  
  5.**配置ssh的免密登陆**
  
  验证是否可以不输入口令就用ssh登陆（目前不可以）

         ssh localhost 
         exit           退出 
  
  ssh免密登陆，需要进行以下配置
  
  - 生成密钥
    
    !一定要在当前用户的主目录下
            
        cd   
    
特点:[icss@master ~]

        ssh-keygen -t rsa

生成ssh 密码，并用rsa进行加密，一路回车

        ls .sub
        id_rsa    私钥
        id_rsa.pub 公钥
>补充：
ls -l 以列表形式显示
ls -la 列出隐含目录

- 生成authorized_keys 

        cat ~/.ssh/id_rsa.pub>>~/.ssh/authorized_keys      全路径

由公钥生成，公钥输出到authorized_keys 。`>`覆盖， `>>`追加

- 设置authorized_keys 文件权限（可读可写）

        chmod 0600 ~/.ssh/authorized_keys

第一位是否可读 第二位是否可写 第三位是否执行

`6` -110 可读可写不可执行

- 验证 

        ssh localhost 免密登录
        exit


3.运行并验证

 - hadoop HDFS 的运行验证

格式化HDFS文件系统：只需要做一次 `bin/hdfs`

        hdfs namenode -format

组成元素 ：命名节点 namenode 伪分布式的单机版，同时是namenode+datenode
格式化namenode 同时找datenode 也进行了格式化

- 启动HDFS 

        sbin/start-dfs.sh
        sbin/start-all.sh
        sbin/stop-dfs.sh
        sbin/stop-all.sh
        
- 验证
`usr/java/jdk.1.8.0-162/bin/jps`

        jps  //java process statue java进程

  显示四个进程：

        NameNode
        SecondaryNameNode
        Jsp
        DataNode



> 如果ssh localhost 没有成功,找不到localhost
 
> su root
  gedit /etc/hosts
         127.0.0.1  localhost master master.hadoop

-------------------

#Hadoop集群模式

 0.环境准备
  
        所有机器:时间正确\安装、配置 JDK\保证网络互通\ping master \ping slave01

**配置ssh的免密登录**
    
前提：所有计算机的用户名icss/密icss 
    
        MASTER : ssh slave01
        SLAVE01 : ssh master
        exit         退出
  
  ----------------      
*可选，删除当前MASTER上的SSH既有文件*
            
        cd 
        cd .ssh 
        rm authorized_keys
        rm id_rsa
        rm id_rsa.pub

  -----------
  
 - 在master上，配置免密登陆
   cd 或者 cd~
    
      - 生成终端密钥
        
            ssh-keygen -t rsa
      - 复制公钥文件到 authorized_keys
            
              cat ~/.ssh/id_rsa.pub>>~/.ssh/authorized_keys
      - 修改权限
    
            chmod 600 ~/.ssh/authorized_keys
      - 将authorized_keys 文件复制到slave01 节点的对应目录下
            
            scp ~/.ssh/authorized_keys icss@slave01:~/

 -------------------
 
 - 在slave01 节点上
        
          cd
          mv authorized_keys .ssh/
    - 生成终端密钥
      
            ssh-keygen -t rsa
    
    - 修改权限
            
            chmod 600 ~/.ssh/authorized_keys
    
    - 将slave01 的公钥信息追加到含有master公钥信息的authorized_keys
        
            cat ~/.ssh/id_rsa.pub>>~/.ssh/authorized_keys
    - 将含有master 和slave01的公钥信息的authorized_keys 复制回master
       
            scp ~/.ssh/authorized_keys icss@master:~/.ssh

    --------------------
    
- 在 master 上， 改 authorized_keys 的权限并验证
     -  修改权限 -- 可选 
                chmod 600 ~/.ssh/authorized_keys
            !! 

>前提：严格按照前面的执行，但是还提问密码：
                eval "$(ssh-agent -s)"
                ssh-add

1. hadoop 下载拷贝解压安装文件 
    
       ` MASTER home/icssp/hadoop/hadoop-3.0.0`
2. 配置文件（7个配置文件）
    
 - 配置hadoop 环境变量
  
   !!!全部在master 下面操作

        cd home/icss/hadoop/hadoop-3.0.0/etc/hadoop
        gedit hadoop-env.sh
        
`export JAVA_HOME=/usr/java/jdk1.8.0_162`
            
- 配置 yarn环境变量 (计算框架的配置文件)
        
        cd home/icss/hadoop/hadoop-3.0.0/etc/hadoop
        gedit yarn-env.sh
        
`export JAVA_HOME=/usr/java/jdk1.8.0_162`

- 
配置核心组件配置文件
    
        cd home/icss/hadoop/hadoop-3.0.0/etc/hadoop
        gedit core-site.xml



 ```  
 home/icss/hadoop/hadoop-3.0.0/etc/hadoop/core-site.xml 
            gedit core-site.xml 
            <configuration>
                <!-- 指明HDFS的访问的地址和端口 -->
                <property>
                    <name>fs.defaultFS</name>
                    <value>hdfs://master:9000</value>
                </property>
                <!-- 指明HDFS分布式文件系统所在的文件目录的位置 -->
                <!-- 要创建该目录 mkdir -->
                <property>
                    <name>hadoop.tmp.dir</name>
                    <value>/home/icss/hadoopdata</value>
                </property>
                <!-- 可以不写 -->
                <property>
                    <name>fs.default.name</name>
                    <value>hdfs://master:9000</value>
                </property>
            </configuration> 
 ```
- 配置 HDFS 配置文件
        
`home/icss/hadoop/hadoop-3.0.0/etc/hadoop/hdfs-site.xml`


        gedit hdfs-site.xml 


```
    <!-- 指明HDFS上文件块的复制|备份份数 -->
    <!-- 如果是两台机器(master&slave01 value 1) -->
    <!-- 如果是三台机器(master&slave01&slave02 value 2) -->
                <property>
                    <name>dfs.replication</name>
                    <value>1</value>
                </property>
```
    
- 配置运算框架|资源管理系统 yarn-site.xml 
           
` home/icss/hadoop/hadoop-3.0.0/etc/hadoop/yarn-site.xml `
            
        gedit yarn-site.xml 
 
```       
            <property>
                    <name>yarn.nodemanager.aux-services</name>
                    <value>mapreduce_shuffle</value>
            </property>   
            <property>
                    <name>yarn.resourcemanager.address</name>
                    <value>master:18040</value>
            </property>  
            <property>
                    <name>yarn.resourcemanager.schedular.address</name>
                    <value>master:18030</value>
            </property>        
            <property>                    
<name>yarn.resourcemanager.resource-tracker.address</name>
                    <value>master:18025</value>
             </property> 
   
            <property>
                    <name>yarn.resourcemanager.admin.address</name>
                    <value>master:18041</value>
            </property>  
            <property>
                    <name>yarn.resourcemanager.webapp.address</name>
                    <value>master:18080</value>
            </property>     
            <property>
            <!-- Hadoop 3.0 必须配置 -->
             <name>yarn.application.classpath</name>
             <value>/home/icss/hadoop/hadoop-3.0.0/etc/hadoop:/home/icss/hadoop/hadoop-3.0.0/share/hadoop/common/lib/*:/home/icss/hadoop/hadoop-3.0.0/share/hadoop/common/*:/home/icss/hadoop/hadoop-3.0.0/share/hadoop/hdfs:/home/icss/hadoop/hadoop-3.0.0/share/hadoop/hdfs/*:/home/icss/hadoop/hadoop-3.0.0/share/hadoop/mapreduce/*:/home/icss/hadoop/hadoop-3.0.0/share/hadoop/yarn:/home/icss/hadoop/hadoop-3.0.0/share/hadoop/yarn/lib/*:/home/icss/hadoop/hadoop-3.0.0/share/hadoop/yarn/*</value>
            </property>
```

- 配置MR mapred-site.xml
            
`home/icss/hadoop/hadoop-3.0.0/etc/hadoop/mapred-site.xml `
           
        gedit mapred-site.xml

```
                <property>
                    <name>mapreduce.framework.name</name>
                    <value>yarn</value>
                </property>
                <property>
                    <name>mapreduce.application.classpath</name>
                    <value>/home/icss/hadoop/hadoop-3.0.0/etc/hadoop:/home/icss/hadoop/hadoop-3.0.0/share/hadoop/common/lib/*:/home/icss/hadoop/hadoop-3.0.0/share/hadoop/common/*:/home/icss/hadoop/hadoop-3.0.0/share/hadoop/hdfs:/home/icss/hadoop/hadoop-3.0.0/share/hadoop/hdfs/*:/home/icss/hadoop/hadoop-3.0.0/share/hadoop/mapreduce/*:/home/icss/hadoop/hadoop-3.0.0/share/hadoop/yarn:/home/icss/hadoop/hadoop-3.0.0/share/hadoop/yarn/lib/*:/home/icss/hadoop/hadoop-3.0.0/share/hadoop/yarn/*</value>
                </property>
                
```

- 配置workers
        
         gedit home/icss/hadoop/hadoop-3.0.0/etc/hadoop/
    

如果是两台机器 master&slave01 
            
            slave01

如果是三台机器 master&slave01&slave02 
            
            slave01
            slave02

-------------------------------- 上述均在master完成---------------------

master hadoop/hadoop3.0.0 --> slave01 对应的目录下

MASTER 
           
            scp -r hadoop icss@slave01:~/
            或者 
            scp -r hadoop slave01:~/ 
3. 运行、验证

- 关闭防火墙 master&slave01|&slave02  root
    
            查看防火墙状态
                systemctl status firewalld.service
            停止防火墙
                systemctl stop firewalld.service
            禁用防火墙
                systemctl disable firewalld.service
            启动防火墙 
                systemctl start firewalld.service


 1. 配置 hadoop 启动的环境变量 -- MASTER icss ` .bash_profile`
        
            gedit .bash_profile 
                            export HADOOP_HOME=$HOME/hadoop/hadoop-3.0.0
                export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH

 2. 创建 hadoop 数据文件目录 -- 在所有的机器上 
           
            cd 
            mkdir hadoopdata 
        -- 启动 Hadoop 集群 master icss 
 3. 格式化文件系统
            
            hdfs namenode -format 

    - 验证：
    
    
                 cd hadoopdata/
                -dfs
    
                 cd dfs/
                -name
    
                cd name/
                -current
        
                cd current/
                 ls
        
        
 4. 启动集群 
            
            start-dfs.sh 
            start-yarn.sh 
    ---合并一个命令
            
            start-all.sh 



------------------------------

# 7-5遇到的问题

>hadoop@namenode:~$ ssh localhost
The authenticity of host 'localhost (127.0.0.1)' can't be established.
ECDSA key fingerprint is c0:b3:7d:6d:17:94:02:e1:e4:67:39:4f:08:ff:74:cf.
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added 'localhost' (ECDSA) to the list of known hosts.
hadoop@localhost's password:
… …


master 可以免密登陆，但是slave01不可以，slave01也不能免密自己

关键在**Warning: Permanently added 'localhost' (ECDSA) to the list of known hosts.**

出现这种警告，原因是文件夹以及文件.ssh的读写权限问题
把.ssh删除，再用icss 新建

        mkdir .ssh

用icss 更改权限为

        chmod 700 ~/.ssh

就能实现免密登陆啦~

----------------------

## 补充：

>   Master作为客户端，要实现无密码公钥认证，连接到服务器Salve（DataNode |Tasktracker）上时，需要在Master上生成一个密钥对，包括一个公钥和一个私钥，而后将公钥复制到所有的Slave上。

>   当Master通过SSH连接Salve时，Salve就会生成一个随机数并用Master的公钥对随机数进行加密，并发送给Master。Master收到加密数之后再用私钥解密，并将解密数回传给Slave，Slave确认解密数无误之后就允许Master进行连接了。这就是一个公钥认证过程，其间不需要用户手工输入密码。

>   重要过程是将客户端Master复制到Slave上。





