# 07-06 -- 07-07 jsoup 爬虫

标签： jsoup 实习 java

---

>实习的老师太实在，干货满满，每天都有新的收获，每天也都能遇到新的问题和困难。

获取数据、对数据存储、数据计算、数据挖掘、数据变现

前期准备的hdfs,一个分布式文件系统来存储数据，用很多台机器组成一个集群，扩充容易，价格便宜来存储数据。

网络爬虫：web 服务器上申请html文件，浏览器作用解析文本文件，按照规则展示出来。

> 科普：
    浏览器根据**内核**进行分类：**渲染引擎**、JS引擎
**渲染引擎**：   
 Trident(IE内核)、Gecko (Firefox内核) 、Presto(Opera前内核)、Webkit(Chrome内核 Safari内核)Blink(google opera )
 

> 多核浏览器：包含多个内核 <i class="icon-bolt" ></i>  blink  ||   E Trident

--------------
解析页面：
```
package myspider;

import java.io.BufferedReader;
import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.net.MalformedURLException;
import java.net.URL;

public class GetFootballData {
		public static void main(String[] args) throws IOException {
		    //借助URL &JAVA IO获取页面内容
			String address="http://footballresults.org/league.php?league=EngDiv1";
			//初始化URL类
			URL url=new URL(address);
			//获取URL 对应的流数据，包装成reader
			InputStreamReader isr =new InputStreamReader(url.openStream(),"utf-8");
			//再包装 成buffer 可以一行一行读
			BufferedReader br=new BufferedReader(isr);
			String content ="";//初值
			while((content=br.readLine())!=null) {
				System.out.println(content);
				
			}
			
		}
		
}
```
java io实际上通过java input ouput 的流来获取，得到远程文件的流，openstream读到本地进行处理。
inputstreamreader 只能以读字符数组形式。
包装成 bufferedreader 可以一行一行的读

页面是一个文本流，读文本流+reader-->包装成reader ,后缀是reader的话就是读取文本。

java里面最好的html框架就是jsoup

```
package myspider;

import java.io.IOException;
import java.util.Iterator;

import org.jsoup.Connection;
import org.jsoup.Jsoup;
import org.jsoup.nodes.Document;
import org.jsoup.nodes.Element;
import org.jsoup.select.Elements;

public class GetDoubanData {
	
	public static void main(String[] args) throws IOException {
		String url="https://movie.douban.com/review/best/";
		int pageNum= 0 ;
		String pagePrefix="?start=";
		url=url+pagePrefix+String.valueOf(pageNum*20);
		
		Connection conn=Jsoup.connect(url);
		Document document=conn.get();
		//返回是文档 ，HTML 
		
		Elements headers = document.select("header.main-hd");
		//jsoup 好处是可以找document的东西 ，类选择器（组成部分）
		
		Iterator<Element> headerIterator =headers.iterator();
		while(headerIterator.hasNext()) {
			Element header=headerIterator.next();
			Elements name=header.getElementsByClass("name");
			String username=name.text();
			System.out.println(username);
		}
	}
}
```


数字变成字符串string.valueof()

关键词：反查机制模拟成浏览器，hidden 
        绑定cookie以后登陆
        IP池
        




**指定URL** ->**通过url连接来获取最终的页面**

解析页面，提取元素

```

package myfirst;

import java.io.IOException;
import java.util.HashMap;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Set;

import org.jsoup.Connection;
import org.jsoup.Connection.Method;
import org.jsoup.Connection.Response;
import org.jsoup.Jsoup;
import org.jsoup.nodes.Document;
import org.jsoup.nodes.Element;
import org.jsoup.select.Elements;

public class logingit {

	public static void main(String[] args) throws IOException {
		String Login_Url = "https://github.com/login";
		String User_Agent = "User-Agent";
		String User_Agent_Value ="Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36";
		
		String username = "455090116@qq.com";
		String password = "chenjie4U";

		Connection conn = Jsoup.connect(Login_Url);
		conn.header(User_Agent, User_Agent_Value);
		
		Response response = conn.execute(); //获取相应
		Document doc = Jsoup.parse(response.body()); //包装成html
		
		Elements forms = doc.select("form");
		Element form = forms.first();

		Map<String, String> parameters = new HashMap<String, String>();
		
		for (Element e : form.getAllElements()) {
			if (e.attr("name").equals("login")) {
				e.attr("value", username);
			}
			if (e.attr("name").equals("password")) {
				e.attr("value", password);
			}
			if (e.attr("name").length() > 0)
				parameters.put(e.attr("name"), e.attr("value"));
		}
		//第二次请求
		String urlLogin = "https://github.com/session";
		Connection conn2 = Jsoup.connect(urlLogin);
		conn2.header(User_Agent, User_Agent_Value);
		
		Response loginResponse = conn2
			.ignoreContentType(true) //略过编码类型
			.followRedirects(true)  //允许重定向
			.method(Method.POST)
			.data(parameters)   
			.cookies(response.cookies())
			.execute();
			
	//遍历map 中的元素		
		System.out.println(loginResponse.body());
		Map<String, String> cookies = loginResponse.cookies();
		for (String key : cookies.keySet()) {
			System.out.println(key + " : " + cookies.get(key));
		}
		
		// 二次登录
		String urlLoginSecond = "https://github.com";
		Connection conn3 = Jsoup.connect(urlLoginSecond);
		conn2.header(User_Agent, User_Agent_Value);
		
		Response loginSecondResponse = conn3
				.cookies(loginResponse.cookies())
				.execute();
		System.out.println(loginSecondResponse.body());
	}
}

```

>补充：
>Map是一种依照键（key）存储元素的容器，键（key）很像下标，在List中下标是整数。在Map中键（key）可以使任意类型的对象。Map中不能有重复的键（Key），每个键（key）都有一个对应的值（value）

>connect(String url) 方法创建一个新的 Connection, 和 get() 取得和解析一个HTML文件

-------------------


要取得一个属性的值，可以使用Node.attr(String key) 方法

对于一个元素中的文本，可以使用Element.text()方法

对于要取得元素或属性中的HTML内容，可以使用Element.html(), 或 Node.outerHtml()方法

- 处理URLs：

  绝对URLs:将相对路径转换后成绝对路径
  ```
  document doc= jsoup .connect(url).get();
  element link= doc.select("a").first();
  string rehref=link .attr ("href");
  
  string abshref= link.attr("abs:href");
  ```
  在HTML元素中，URLs经常写成相对于文档位置的相对路径： <a href="/download">...</a>. 当你使用 Node.attr(String key) 方法来取得a元素的href属性时，它将直接返回在HTML源码中指定定的值。

    假如你需要取得一个绝对路径，需要在属性名前加 abs: 前缀。这样就可以返回包含根路径的URL地址attr("abs:href")



-------------------------
JAVA I/O


流：在程序中所有的数据都是以流的方式进行传输或保存的，程序需要数据的时候要使用输入流读取数据，而当程序需要将一些数据保存起来的时候，就要使用输出流完成。
inputstream输入流 outputstream输出流

没有办法实例化 没有办法做操作

流很抽象，java 装饰器模式，层层包装。

inputstream -> F I S reader buffer
outputstream-> F O S
bow buffer output writter

一个输入流一个输出流 

文件两大类：文本文件、二进制文件



